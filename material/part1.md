# Part 1: Supervised Machine Learning: A Beginner's Guide

Machine Learning is behind many exciting technologies today, like self-driving cars, personalized recommendations, and even medical diagnoses. One of the key approaches to ML is **Supervised Learning**, where the computer learns from examples that include both the input data and the correct outputs. In this reading, we'll explore how this technique works and how it powers real-world applications.

> [!NOTE]  
>  In Parts 1-4 of this activity, the datasets are not fully preprocessed. As an optional bonus task, if your group successfully cleans the data and provides a cleaned dataset, each member will receive a **50-point bonus**.  
> If you need to save a DataFrame (`df`) as a CSV file, you can use the following command: 
`df.to_csv('my_data.csv', index=False)`


-----
## Intro

**1. What is Machine Learning, Briefly?**

At its core, Machine Learning is about teaching computers to learn patterns from data *without* being explicitly programmed for every single scenario. Instead of writing exact rules, we give the computer data and let it figure out the rules itself.

**2. What Makes Learning "Supervised"?**

Imagine you're learning to identify different types of fruit. Your teacher (the "supervisor") shows you an apple and says "This is an apple." Then shows you a banana and says "This is a banana." You learn by connecting the fruit you see (the **input features**, like shape, color, size) with the correct name (the **output label** or **target**).

Supervised Learning works the same way:
*   We feed the computer **labeled data**.
*   This data consists of **input features** (characteristics of something) and the corresponding **correct output label** (the "answer").
*   The computer's goal is to learn a mapping, or a set of rules, to predict the output label for *new, unseen* inputs based on the patterns it learned from the examples.

**3. The Big Picture: A Standard Recipe (The ML Pipeline)**

Just like following a recipe when cooking, there's a standard process, or **pipeline**, that we follow in most supervised learning projects. This helps keep things organized and ensures we cover all the important steps:

-  **Get the Data:** Find and load the dataset you want to learn from.
-  **Clean and Prepare the Data (Preprocessing):** This is super important! Real-world data is often messy. We need to handle missing pieces, make sure everything is in a format the computer understands (like numbers instead of text), and sometimes adjust the scale of numbers. (We saw this clearly in Part 5 of the lab!).
-  **Split the Data:** Divide your data into two parts:
    *   **Training Set:** Used to *teach* the model. (Usually the larger part, like 80%).
    *   **Testing Set:** Used to *evaluate* how well the model learned, using data it hasn't seen before. (Usually the smaller part, like 20%). This prevents the model from just "memorizing" the answers.
-  **Choose Your Tool (The Model):** Select an appropriate algorithm or "model" based on your task.
-  **Teach the Tool (Train the Model):** Feed the *training data* to the model. This is where the learning happens! (`model.fit()`).
-  **Test the Tool (Make Predictions):** Ask the trained model to make predictions on the *testing data's* input features. (`model.predict()`).
-  **Check the Score (Evaluate the Model):** Compare the model's predictions on the test set with the actual known answers (the test set labels). This tells us how well the model performs on unseen data.

-----
##  The Two Main Flavors of Supervised Learning

Based on the *type* of "answer" or label we want to predict, supervised learning splits into two main categories:

*   **Classification (Predicting Categories):**
    *   **Goal:** Assign data points to distinct groups or classes. The output is a category name.
    *   **Examples:**
        *   Will a passenger survive on the Titanic? (*Categories: Survived, Did Not Survive*) - Lab Part 1
        *   What species is this Iris flower? (*Categories: Setosa, Versicolor, Virginica*) - Lab Part 2
        *   Is this email Spam or Not Spam?
    *   **A Classic Tool: Decision Tree:** Imagine a flowchart of yes/no questions. A Decision Tree asks a series of questions about the input features to arrive at a final category prediction.

*   **Regression (Predicting Numbers):**
    *   **Goal:** Predict a continuous numerical value. The output is a number on a scale.
    *   **Examples:**
        *   What is the predicted fuel efficiency (MPG) of this car? (*Value: e.g., 25.5 MPG*) - Lab Part 3
        *   What is the predicted diabetes progression score? (*Value: e.g., 150.0*) - Lab Part 4
        *   What will the temperature be tomorrow?
    *   **A Classic Tool: Linear Regression:** Think of drawing the "best-fit" straight line through data points on a graph. Linear Regression tries to find a linear relationship between the input features and the numerical output value.

<details>
<summary>About the dataset</summary>

### The MPG dataset

The **MPG dataset** (Miles Per Gallon dataset) is a popular dataset used in statistics and machine learning to analyze fuel efficiency of various cars. It originates from the **1974 Motor Trend US magazine** and contains specifications of various automobile models from the **1970s to early 1980s**.

**Dataset Overview**
The dataset includes **398 rows (observations)** and **9 columns (features)**, with some missing values. It is often used to practice **regression analysis**, particularly predicting **fuel efficiency (MPG)** based on car features.

**Features**
1. **mpg** (Miles per gallon) – *Target variable (continuous)*
2. **cylinders** – Number of cylinders (categorical: 4, 6, 8)
3. **displacement** – Engine displacement (cubic inches) (continuous)
4. **horsepower** – Engine horsepower (continuous, some missing values)
5. **weight** – Vehicle weight (in pounds) (continuous)
6. **acceleration** – Time to accelerate from 0 to 60 mph (continuous)
7. **model year** – Year of manufacture (1970-1982) (categorical)
8. **origin** – Country of origin (1 = USA, 2 = Europe, 3 = Japan) (categorical)
9. **car name** – Name of the car (string)

**Common Use Cases**
- **Predicting fuel efficiency** (MPG) using regression models.
- **Feature analysis** to determine which variables influence fuel efficiency the most.
- **Exploratory Data Analysis (EDA)** to identify trends in car performance over time.
- **Machine Learning** applications, including linear regression, decision trees, and neural networks.

### The Diabetes Progression Score

The **Diabetes Progression Score** is a key target variable in a well-known **diabetes dataset** often used for regression analysis in machine learning. This dataset is commonly referred to as the **Diabetes Dataset** from the **Scikit-learn library**, which originates from medical research.

**Overview of the Diabetes Dataset**
- The dataset is based on a study of **diabetes progression** in patients.
- It includes **442 observations** (patients) and **10 features** related to health metrics.
- The **target variable** is a **continuous numeric score** representing **disease progression one year after baseline**.

**Features (Predictors)**
The dataset contains 10 baseline variables (all numeric and standardized), which are:
1. **Age** – Patient’s age in years.
2. **Sex** – A binary variable representing sex.
3. **BMI** – Body Mass Index (a measure of body fat based on height and weight).
4. **Blood Pressure** – Average blood pressure.
5. **S1-S6 (Six blood serum measurements)** – Various biochemical markers in the blood.

**Target Variable**
- The **diabetes progression score** is a **quantitative measure** of how diabetes has progressed **one year after the baseline measurement**.
- Higher scores indicate **worse** progression of the disease.

**Use Cases**
- **Regression Analysis**: Predicting the progression score using features like BMI, blood pressure, and serum measurements.
- **Feature Importance**: Identifying which factors most strongly influence diabetes progression.
- **Medical Research**: Understanding diabetes trends and patient health over time.
- **Machine Learning Models**: Used for training and evaluating regression models.


</details>


-----
##  How Do We Know if the Model is Any Good? (Evaluation)

Training a model isn't enough; we need to know if it actually learned well! That's why we use the **Testing Set** – data the model never saw during training.

*   For **Classification**, we often look at **Accuracy** (what percentage did it get right overall?). We also use metrics like **Precision** and **Recall** to understand specific types of errors (covered in the lab summary).
*   For **Regression**, accuracy doesn't make sense. Instead, we measure the *error*, how far off were the predictions on average? Metrics like **Mean Absolute Error (MAE)** or **Mean Squared Error (MSE)** tell us this. We also use **R-squared (R²)** to see how much of the variation in the real answers our model could explain.

**6. The Reality Check: Why Cleaning Data Matters (Preprocessing)**

As we saw in Part 5 of the lab with the raw 'Auto MPG' data, real datasets aren't perfect. They might have:

*   **Missing Values:** Blank spots where data should be.
*   **Categorical Data:** Text descriptions (like 'USA', 'Europe', 'Japan') that models can't directly use.
*   **Different Scales:** Some numbers might be huge (like car weight) while others are small (like number of cylinders), which can confuse some models.

**Preprocessing** is the step where we fix these issues:
*   We **impute** (fill in) missing values reasonably.
*   We **encode** categorical text into numerical representations (like One-Hot Encoding).
*   We **scale** numerical features so they are on a more level playing field (like Standardization).

*Without good preprocessing, even the best model might perform poorly!*

-----
## Putting it All Together

Supervised Learning is a powerful technique where we teach computers by showing them examples with answers (labeled data). We follow a standard pipeline: get data, clean it (preprocess!), split it, choose a model (like a Decision Tree for categories or Linear Regression for numbers), train it, test it, and evaluate how well it learned. Understanding this process is your first big step into the world of building intelligent systems!

-----
## FAQ


**1. Why is Accuracy Not Enough in Classification?**
Accuracy alone can be misleading, especially when dealing with **imbalanced datasets**. This is because accuracy simply measures how many predictions are correct, but it doesn't distinguish between **false positives** and **false negatives**, which can be critical in certain applications.

**Example: Medical Diagnosis**
Imagine a classification model predicting whether a patient has a **rare disease**:
- 990 patients **don’t** have the disease.
- 10 patients **do** have the disease.

If the model **always predicts "No disease"**, it will be correct for 990 out of 1000 patients, giving an **accuracy of 99%**. However, it completely **fails to detect any actual cases**, which is dangerous.

This is why we need **Precision and Recall**:

- **Precision** (Positive Predictive Value) – Measures how many of the predicted positive cases were actually correct. High precision means fewer false positives.
- **Recall** (Sensitivity) – Measures how many of the actual positive cases were correctly identified. High recall means fewer false negatives.

For a disease prediction model, **high recall** is crucial because missing a real case (false negative) could be life-threatening.

---

**2. What is a Confusion Matrix?**
A **Confusion Matrix** is a table used to evaluate the performance of a classification model. It shows the number of:
- **True Positives (TP)** – Correctly predicted positive cases.
- **False Positives (FP)** – Incorrectly predicted as positive (Type I error).
- **False Negatives (FN)** – Incorrectly predicted as negative (Type II error).
- **True Negatives (TN)** – Correctly predicted negative cases.

#### **Example of a Confusion Matrix for a Binary Classifier:**
| Actual \ Predicted | Positive (1) | Negative (0) |
|--------------------|-------------|-------------|
| **Positive (1)**   | TP (Correct) | FN (Missed case) |
| **Negative (0)**   | FP (False alarm) | TN (Correct) |

From this matrix, we can calculate:
- **Accuracy** = (TP + TN) / (TP + FP + TN + FN)
- **Precision** = TP / (TP + FP)
- **Recall (Sensitivity)** = TP / (TP + FN)
- **F1-score** = 2 × (Precision × Recall) / (Precision + Recall) (harmonic mean of precision & recall)


**3. MAE, MSE, and RMSE in Regression**  

When evaluating a **regression model**, we often use error metrics to measure how far the predictions are from the actual values. The three most common metrics are:  

- **Mean Absolute Error (MAE)**  
   - Measures the average absolute difference between predicted and actual values.  
   - Formula:  
     \[
     MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
     \]
   - **Pros:** Easy to interpret, gives equal weight to all errors.  
   - **Cons:** Does not emphasize large errors.  

- **Mean Squared Error (MSE)**  
   - Measures the average squared difference between predicted and actual values.  
   - Formula:  
     \[
     MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
     \]
   - **Pros:** Penalizes larger errors more than smaller ones, making it useful when large errors need to be avoided.  
   - **Cons:** Squaring the errors makes the metric harder to interpret in the original unit.  

- **Root Mean Squared Error (RMSE)**  
   - Square root of MSE, which brings the error back to the original unit.  
   - Formula:  
     \[
     RMSE = \sqrt{MSE}
     \]
   - **Pros:** More interpretable than MSE because it’s in the same unit as the target variable.  
   - **Cons:** Still penalizes large errors more than small ones.  

**Which One is Better?**  
- **MAE** is better when you want an interpretable, balanced metric that treats all errors equally.  
- **MSE and RMSE** are better when larger errors are more concerning, as they penalize big mistakes more heavily.  
- **RMSE** is often preferred in practical applications because it maintains the units of the target variable while still emphasizing larger errors.  


---
## Further Exploration

For more information, please refer to this reading:

- [Introduction to Supervised Learning](https://developers.google.com/machine-learning/intro-to-ml/supervised)
- [Linear regression](https://developers.google.com/machine-learning/crash-course/linear-regression)
- [Classification](https://developers.google.com/machine-learning/crash-course/classification)
- [Algorithms for Supervised machine learning](https://scikit-learn.org/stable/supervised_learning.html)
- Video Course: Intro to Machine Learning with Python
  - [Part 4: Train a Classification Model](https://www.youtube.com/watch?v=f3kSEebz8QA)
  - [Part 5: Cross-Validation and Identifying Misclassified Points](https://www.youtube.com/watch?v=cEs7UfimlEk)
  - [Part 6: Model Tuning and Test Set Accuracy](https://www.youtube.com/watch?v=eU6Jr9DpcrQ)
 - [Part 7: Wrap-Up](https://www.youtube.com/watch?v=zI58IQpE2uE)  



<!-- 

- K-NN for Classification/Regression
- `DecisionTreeClassifier()`/ `DecisionTreeRegressor()` 
-->
